{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "16kWd3P13I6SWkJ328R8Ju5rT-tvj6MaU",
      "authorship_tag": "ABX9TyOAMeRDqZOMCVs5TyB2Xj/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reganmeloche/mrpc_paraphrase/blob/main/semantic_similarity_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Paraphrase Detection - Semantic Similarity Approach\n"
      ],
      "metadata": {
        "id": "D_sdHaHiv-p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will be following the approach laid out in the following paper: https://ieeexplore.ieee.org/document/8639211\n"
      ],
      "metadata": {
        "id": "_zKr-lTTInBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "LsCnCcOLIy22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv"
      ],
      "metadata": {
        "id": "Sk1X_qX8wGDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_PATH = '/content/drive/MyDrive/Colab Notebooks/NLP/ms_paraphrase'"
      ],
      "metadata": {
        "id": "noiDBzTLI265"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = f'{ROOT_PATH}/data'\n",
        "\n",
        "train_df = pd.read_csv(f'{data_path}/train_df.csv')\n",
        "test_df = pd.read_csv(f'{data_path}/test_df.csv')"
      ],
      "metadata": {
        "id": "xXeVd7N4I5Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "id": "HBUAYtPTI7F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "gEjpa7zjJDq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will perform some basic preprocessing and normalization of the sentences using the nltk library"
      ],
      "metadata": {
        "id": "SqITSzPnJFY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IFLxivlLNC6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "HosaF5HJJmfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove dashes\n",
        "    text = text.replace(\"-\", \" \")\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = ''.join(c for c in text if c not in punctuation)\n",
        "\n",
        "    # Tokens\n",
        "    tokens = [word for word in nltk.word_tokenize(text)]\n",
        "\n",
        "    # Remove stop words\n",
        "    non_sw = [t for t in tokens if t not in stop_words]\n",
        "    text = ' '.join(t for t in non_sw)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "xCb88apSJCxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = 'I took the 3 dogs for a walk last Tuesday at 8pm!'\n",
        "sample_prepro = preprocess(sample_text)\n",
        "print(sample_prepro)"
      ],
      "metadata": {
        "id": "08ndjMdTJv7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we will write a function that will format our input dataframe by iterating over the preprocess function. The result is a tuple, containing the sentence pairs (in another tuple) and the corresponding labels (1 or 0)"
      ],
      "metadata": {
        "id": "nDLhHz7MKZEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_df(df):\n",
        "    s1_list = df['s1'].apply(preprocess).values\n",
        "    s2_list = df['s2'].apply(preprocess).values\n",
        "    labels = df['label'].values\n",
        "    sentence_pairs = list(zip(s1_list, s2_list))\n",
        "    return sentence_pairs, labels"
      ],
      "metadata": {
        "id": "cRCDkYaLJ3po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = format_df(train_df) \n",
        "\n",
        "print(X[0])"
      ],
      "metadata": {
        "id": "4nM_iOH4K0KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Vectors"
      ],
      "metadata": {
        "id": "uLhTd4FILGFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our text is preprocessed, we want to extract word vectors. In our baseline approach, we used simple TFIDF vectors, which was based on counts of the words in the training set. In this approach we are going to use word embeddings, which are learned vector representations from a larger training corpus of generic text.\n",
        "\n",
        "We are going to make use of the gensim library, which contains a variety of word embeddings that differ in vector dimension and also training corpus. We could potentially experiment with many of these and compare results. For now we will choose a fairly robust one: glove-wiki-gigaword-300. This can take a while to download.\n",
        "\n",
        "Once it is downloaded, we can look up a word to see the 300-dimensional vector embedding of that word. Some more obscure words may not appear in the embedding. We will discuss how to handle those next."
      ],
      "metadata": {
        "id": "PToHiJhtLvM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "\n",
        "print(list(gensim.downloader.info()['models'].keys()))\n"
      ],
      "metadata": {
        "id": "Yo9hBwSMK7Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = gensim.downloader.load('glove-wiki-gigaword-300')"
      ],
      "metadata": {
        "id": "0KZPGFGzMUil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.get_vector('turkey')"
      ],
      "metadata": {
        "id": "bS3k8OCVNlUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One consideration that we must address is how we handle out-of-vocabulary (OOV) words, i.e. words that appear in our data but not in the training corpus. \n",
        "\n",
        "Our strategy is as follows: Every time we encounter an OOV word, we will generate a random 300-dimensional vector of values between -1 and 1. We will keep a dictionary of these random vectors in storage so that if we encounter that OOV word *again*, then it will have a vector representation.\n",
        "\n",
        "We will now define a class that lets us get the word vectors for all the words in a given sentence. We simply look up each word in our embedding vocabulary. If it is there, then return the vector. If not, then we generate our random vector and store it in the dictionary. The class also handles the dictionary of random OOV vectors. \n",
        "\n",
        "We will also add a function that allows us to calculate the cosine similarity for two words, which we will make use of shortly"
      ],
      "metadata": {
        "id": "b0ss1WSmM1DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import spatial\n",
        "\n",
        "class EmbeddingWrapper:\n",
        "    def __init__(self, embedding, vector_dim=300):\n",
        "        self.__rand_dict = {}\n",
        "        self.__embedding = embedding\n",
        "        self.__vector_dim = vector_dim\n",
        "    \n",
        "    def get_sentence_vec(self, sentence):\n",
        "        result = []\n",
        "\n",
        "        for w in sentence.split(' '):\n",
        "            next_v = self.get_word_vec(w)\n",
        "            result.append(next_v)\n",
        "        \n",
        "        return result\n",
        "    \n",
        "\n",
        "    def get_word_vec(self, w):\n",
        "        result = None\n",
        "        if w in self.__embedding.vocab:\n",
        "            result = self.__embedding.get_vector(w) \n",
        "        else:\n",
        "            if w not in self.__rand_dict:\n",
        "                v = np.random.random(self.__vector_dim) * 2 - 1 # Generate a random vector\n",
        "                self.__rand_dict[w] = v\n",
        "            result = self.__rand_dict[w]\n",
        "        \n",
        "        return result\n",
        "    \n",
        "\n",
        "    def get_distance(self, w1, w2):\n",
        "        e1 = self.get_word_vec(w1)\n",
        "        e2 = self.get_word_vec(w2)\n",
        "        result = 1 - spatial.distance.cosine(e1, e2)\n",
        "        return round(result,3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "saTSQUPgh0p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ew = EmbeddingWrapper(embedding, 300)"
      ],
      "metadata": {
        "id": "2pJ9DrGbiWV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_vec = ew.get_sentence_vec(X[0][0])\n",
        "\n",
        "ew.get_distance('cat', 'dog')"
      ],
      "metadata": {
        "id": "ennHbUcKiZoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Similarity Calculations"
      ],
      "metadata": {
        "id": "mbrrWBT3PiWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our paraphrase determination will consist of several steps. For a given sentence pair, we are going to calculate a combination of similarity metrics and then mesh them together.\n",
        "\n",
        "The first similarity calculation tool we use will be the cosine similarity that we previously defined.\n",
        "\n",
        "The second tool we use will be WordNet. WordNet allows us to enter a word to get its synset, which is a collection of semantic information about a word, including relationships to other words that have a similar meaning. The synset object has a path similarity function that we will leverage\n"
      ],
      "metadata": {
        "id": "s72KecS1RrHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wn_sim(w1, w2):\n",
        "        try:\n",
        "            # Could improve here - get the actual wordnet pos type and extract the proper synset, rather than just the first one\n",
        "            a = wn.synsets(w1)[0]\n",
        "            b = wn.synsets(w2)[0]\n",
        "            result = a.path_similarity(b)\n",
        "        except:\n",
        "            #print(f'oops: {s1, s2}')\n",
        "            result = 0\n",
        "\n",
        "        return round(result, 3)"
      ],
      "metadata": {
        "id": "25wsmGX5nOhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_wn_calc = get_wn_sim('cat', 'dog')\n",
        "print(test_wn_calc)"
      ],
      "metadata": {
        "id": "2peKskUVnrbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now given two words, we have two measurements we can apply - the wordnet similarity metric and the cosine distance on the word embeddings. Our goal is to check if two *sentences* are similar - not individual words. Our determination of sentence similarity will be based on the individual similarities of the words. In this way, we are ignoring the sequential nature of the text, which is a considerable weakness.\n",
        "\n",
        "We will combine these two scores into a single score by applying a weighting. The cosine distance will get a weight of 0.75, and the wordnet similarity gets a weight of 0.25. We will call this the *joint similarity*. We will need to pass in our embedding wrapper as well.\n"
      ],
      "metadata": {
        "id": "BE9JvXPen6l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_joint_similarity(ew, s1, s2, do_print=False):\n",
        "        results = []\n",
        "\n",
        "        for w1 in s1.split(' '):\n",
        "            res_row = []\n",
        "            for w2 in s2.split(' '):\n",
        "                a = ew.get_distance(w1, w2)\n",
        "                b = get_wn_sim(w1, w2)\n",
        "                next_res = round(0.75 * a + 0.25 * b, 3)\n",
        "                if do_print: print(f'{w1}/{w2}: {a}, {b} -> {next_res}')\n",
        "                res_row.append(next_res)\n",
        "\n",
        "            results.append(max(res_row))\n",
        "\n",
        "        if do_print: print(results)\n",
        "        final_result = np.average(results)\n",
        "        return round(final_result, 3)"
      ],
      "metadata": {
        "id": "6MJCNu8ipC4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at a quick example. Suppose we have two sentences:\n",
        "- The bird in the bush\n",
        "- The cat in the bag\n",
        "\n",
        "Once these have been preprocessed, they are simplified to:\n",
        "- bird bush\n",
        "- cat bag\n",
        "\n",
        "We want to measure how similar these sentences are. Let's look at the scores for each word pairing. Each pair shows the cosine distance followed by wordnet similarity, followed by the joint similarity\n",
        "- bird/cat: 0.398, 0.143 -> 0.334 \n",
        "- bird/bag: 0.118, 0.091 -> 0.111\n",
        "- bush/cat: 0.051, 0.077 -> 0.057\n",
        "- bush/bag: 0.1, 0.091 -> 0.098\n",
        "\n",
        "For each word in the first sentence, we will take the maximum score from the words in the second sentence. So for the word \"bird\", we use 0.334, and for the word \"bush\", we use 0.098. Finally, we take an average of these values.\n"
      ],
      "metadata": {
        "id": "GdkRBHnEqE-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = 'bird bush'\n",
        "s2 = 'cat bag'\n",
        "\n",
        "ss1 = calculate_joint_similarity(ew, s1, s2, do_print=True)\n",
        "\n",
        "print(ss1)"
      ],
      "metadata": {
        "id": "17-HhoYCpopm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will perform this calculation again, but will consider s2 as our first sentence. We can then take the average of these two results to get $S_a$"
      ],
      "metadata": {
        "id": "c5XOtsT4sPEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss2 = calculate_joint_similarity(ew, s2, s1, do_print=True)\n",
        "print(ss2)\n",
        "\n",
        "score1 = (ss1 + ss2) / 2\n",
        "\n",
        "print(f'\\nAveraged joint score: {score1}')"
      ],
      "metadata": {
        "id": "JmzXEaULsepA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to incorporate one more score into our system. We mentioned that we are ignoring the word order in our previous calculation, which is a weakness. This next scoring mechanism will account for the order by building a word order vector for each sentence.\n",
        "\n",
        "Let's consider two sentences from the paper:\n",
        "- s1: big mouse clobbers small cat\n",
        "- s2: small cat clobbers big mouse\n",
        "\n",
        "We first take all the unique words in our sentences and assign them an index: { 1-big, 2-mouse, 3-clobbers, 4-small, 5-cat }. Then we build a vector showing the word order index. \n",
        "\n",
        "For s1, this vector is v1 = [1,2,3,4,5]. For s2, it is v2 = [4,5,3,1,2]\n",
        "\n",
        "Our score $S_b$ is calculated as follows:\n",
        "\n",
        "$S_b = 1 - \\frac{\\lVert V_1 - V_2 \\rVert}{\\lVert V_1 + V_2 \\rVert} $.\n",
        "\n",
        "When terms match up between the two sentences (e.g. \"clobbers\"), then $V_1 - V_2$ will get a zero term. This is the numerator of the fraction, so it push the entire fraction lower. Since we're subtracting the fraction from 1, this will yield a higher result. Therefore this score rewards sentences that have alignment in word order between the same word.\n",
        " \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kkCJN2uUs-M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_word_order_similarity(s1, s2):\n",
        "    a = s1.split(' ')\n",
        "    b = s2.split(' ')\n",
        "    all_words = np.concatenate((a,b))\n",
        "    word_set = set(all_words)\n",
        "\n",
        "    v1 = np.zeros(len(word_set))\n",
        "    v2 = np.zeros(len(word_set))\n",
        "\n",
        "    for i, w in enumerate(word_set):\n",
        "        for j in range(len(a)):\n",
        "            if w == a[j]:\n",
        "                v1[i] = j+1 \n",
        "        \n",
        "        for k in range(len(b)):\n",
        "            if w == b[k]:\n",
        "                v2[i] = k+1\n",
        "    \n",
        "    nx1 = np.linalg.norm(v1-v2)\n",
        "    nx2 = np.linalg.norm(v1+v2)\n",
        "\n",
        "    return 1 - (nx1/nx2)"
      ],
      "metadata": {
        "id": "UWGeCkeQtBvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = 'big mouse clobbers small cat'\n",
        "s2 = 'small cat clobbers big mouse'\n",
        "sb = calculate_word_order_similarity(s1, s2)\n",
        "print(sb)"
      ],
      "metadata": {
        "id": "pohJE16TxvkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Putting it all together"
      ],
      "metadata": {
        "id": "6cGjkIgeyq53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have all of our scoring pieces. Now we just need to put them all together and decide how we want to weight the different scores. We perform the weighting using the delta parameter, which is between 0 and 1. The final score calculation is as follows:\n",
        "\n",
        "$S = (\\delta \\cdot S_a) + (1 - \\delta) \\cdot S_b$\n",
        "\n",
        "\n",
        "A high delta will emphasize the averaged joint score $S_a$, and a low delta will emphasize the word order sscore $S_b$\n",
        "\n",
        "We define a class to bring this calculation together. We add the following functions\n",
        "- Predict: We will use this later once a threshold is determined for deciding if a pair of sentences match\n",
        "- calculate_all: Given a set of sentence pairs, calcuate all their scores and return it as a list\n",
        "- calculate_pair_similarity: Calculates the similarity score for a single pair"
      ],
      "metadata": {
        "id": "nKVB7F6Wx9N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimilarityCalculator:\n",
        "    def __init__(self, embedding_wrapper, delta):\n",
        "        self.__ew = embedding_wrapper\n",
        "        self.__delta = delta\n",
        "    \n",
        "    def predict(self, X, threshold):\n",
        "        y_probs = self.calculate_all(X)\n",
        "        results = [1 if y_prob > threshold else 0 for y_prob in y_probs]\n",
        "        return results\n",
        "\n",
        "\n",
        "    def calculate_all(self, X):\n",
        "        results = []\n",
        "\n",
        "        for i,x in enumerate(X):\n",
        "            #if i%50==0: print(i)\n",
        "            next_res = self.calculate_pair_similarity(x[0], x[1])\n",
        "            results.append(next_res)\n",
        "\n",
        "        return results\n",
        "\n",
        "        \n",
        "    def calculate_pair_similarity(self, s1, s2):\n",
        "        ss1 = calculate_joint_similarity(self.__ew, s1, s2)\n",
        "        ss2 = calculate_joint_similarity(self.__ew, s2, s1)\n",
        "\n",
        "        s_a = (ss1 + ss2) / 2\n",
        "        s_b = calculate_word_order_similarity(s1, s2)\n",
        "\n",
        "        return (self.__delta * s_a) + ((1 - self.__delta) * s_b)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7JfzT4eXkUce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SimilarityCalculator(ew, 0.6)\n",
        "\n",
        "result = sc.calculate_pair_similarity('small cat clobbers big mouse', 'big mouse clobbers small cat')\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "a2YvPz67REPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning a threshold"
      ],
      "metadata": {
        "id": "JU4BNI0YzOuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like we did with the TFIDF approach, we will now use our training data to learn the ideal threshold. This training can take a while due to the use of some of our internal tools, such as calls to wordnet.\n",
        "\n",
        "We only consider the pairs that are considered a match, and we take their average score to get our prediction threshold."
      ],
      "metadata": {
        "id": "1rFYlXqXzgeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances = sc.calculate_all(X)\n"
      ],
      "metadata": {
        "id": "9hdJ_B0wRHJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to keep only those that are labeled as a paraphrase\n",
        "matches = [d for i,d in enumerate(distances) if y[i] == 1]\n",
        "\n",
        "# calculate the average\n",
        "threshold = np.average(matches)"
      ],
      "metadata": {
        "id": "qhgrlzMI0OHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold"
      ],
      "metadata": {
        "id": "DIKO2fmM0EhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test set and Evaluation"
      ],
      "metadata": {
        "id": "FGQdU_EFBvUH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can use the threshold value and make predictions on the test set. Finally we can evaluate our performance against the actual labels for the test\n"
      ],
      "metadata": {
        "id": "E9AwH-gFBy7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.58"
      ],
      "metadata": {
        "id": "XMc18LrpEMUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, y_test = format_df(test_df) "
      ],
      "metadata": {
        "id": "LFk6xOQI_2jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = sc.predict(X_test, threshold)"
      ],
      "metadata": {
        "id": "NqiJDPIAB4qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "sy54BJOMCvKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7R1v3giaD9lw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}