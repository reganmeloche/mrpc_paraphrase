{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"1tcVOwQtrCwA577cdECYPt19LXqG_uDOs","authorship_tag":"ABX9TyO8VWAYi5ZMXkjt/g+2m4UA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NLP Paraphrase Detection Data Cleaning"],"metadata":{"id":"Vntj69FisgYs"}},{"cell_type":"markdown","source":["We will be using the [MRPC corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52398) to build a series of paraphrase detection classifiers.\n","\n","We will be taking multiple approaches with this data. So the first thing we want to do is have a look at our data, do some preliminary cleaning, and store it in a usable form, which we will make use of in later notebooks."],"metadata":{"id":"QqjWsEHYsjDc"}},{"cell_type":"code","source":["import pandas as pd\n","import csv"],"metadata":{"id":"7KIARL4htWu6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ROOT_PATH = '/content/drive/MyDrive/Colab Notebooks/NLP/ms_paraphrase'"],"metadata":{"id":"3nZaCBaxsfkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = f'{ROOT_PATH}/data'\n","\n","train_file = f'{data_path}/msr_paraphrase_train.txt'\n","test_file = f'{data_path}/msr_paraphrase_test.txt'\n","\n","train_df = pd.read_csv(train_file, delimiter='\\t', quoting=csv.QUOTE_NONE)\n","test_df = pd.read_csv(test_file, delimiter='\\t', quoting=csv.QUOTE_NONE)"],"metadata":{"id":"CLFTnayssyuJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Viewing the data\n","# train_df.head()\n","# test_df.head()\n","# train_df.info()\n","# test_df.info()"],"metadata":{"id":"yj_PnfnFtuz1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"pKvr90jjtlMU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df.head()"],"metadata":{"id":"FaTyGv0RtmVl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next we will remove the ID columns since those are not needed and do some simple renaming"],"metadata":{"id":"QAmnEd-Rt_Vh"}},{"cell_type":"code","source":["def format_data(df):\n","    new_df = df[['#1 String', '#2 String', 'Quality', ]]\n","    new_df = new_df.rename(columns={'Quality': 'label', '#1 String': 's1', '#2 String': 's2'})\n","    return new_df"],"metadata":{"id":"DAWPXd-0tpwo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = format_data(train_df)\n","test_df = format_data(test_df)"],"metadata":{"id":"24bbb5hOubom"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.head()"],"metadata":{"id":"py8ZuMh0ucyk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now let's save the data in a csv so we can use it for our classifiers"],"metadata":{"id":"n6oX7cxUu-eC"}},{"cell_type":"code","source":["train_df.to_csv(f'{data_path}/train_df.csv', index=False)\n","test_df.to_csv(f'{data_path}/test_df.csv', index=False)"],"metadata":{"id":"cuwr5lTSu1fO"},"execution_count":null,"outputs":[]}]}